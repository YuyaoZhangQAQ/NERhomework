{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangyuyao/opt/anaconda3/envs/tch12/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.nn import Embedding\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentence (df: pd.DataFrame, sentences: list):\n",
    "    for i in range(df.__len__()):\n",
    "        df.context[i].split()\n",
    "        sentence = [[j, \"O\"] for j in df.context[i].split()]\n",
    "        for label in df.labels[i]:\n",
    "            if label[\"end_position\"] is not None :\n",
    "                for sp in label[\"start_position\"]:\n",
    "                    sentence[sp][1] = \"B-\" + label[\"entity_label\"]\n",
    "                for sl in label[\"span_list\"]:\n",
    "                    for idx in range(sl[0][0] + 1, sl[0][1] + 1):\n",
    "                        sentence[idx][1] = \"I-\" + label[\"entity_label\"]\n",
    "        sentences.append([df.context[i], [i[1] for i in sentence]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20741"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 加载所有句子，用于构建总词典\n",
    "all_sentences = []\n",
    "df = pd.read_json(\"/Users/zhangyuyao/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/3b589b8fb0516c8e072f981ad5ce1b32/Message/MessageTemp/9a8944b8b79ab3df4a4f9e99ebae488b/File/第一次作业布置22.09.27/data/conll03/train.json\")\n",
    "read_sentence(df, all_sentences)\n",
    "df = pd.read_json(\"/Users/zhangyuyao/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/3b589b8fb0516c8e072f981ad5ce1b32/Message/MessageTemp/9a8944b8b79ab3df4a4f9e99ebae488b/File/第一次作业布置22.09.27/data/conll03/test.json\")\n",
    "read_sentence(df, all_sentences)\n",
    "df = pd.read_json(\"/Users/zhangyuyao/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/3b589b8fb0516c8e072f981ad5ce1b32/Message/MessageTemp/9a8944b8b79ab3df4a4f9e99ebae488b/File/第一次作业布置22.09.27/data/conll03/dev.json\")\n",
    "read_sentence(df, all_sentences)\n",
    "all_sentences.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30288"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set()\n",
    "for sentence in all_sentences:\n",
    "    words_list = sentence[0].split()\n",
    "    for word in words_list :\n",
    "        words.add(word)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize时的字典\n",
    "words_dict = {}\n",
    "for i, word in enumerate(words):\n",
    "    words_dict[word] = i + 1\n",
    "words_dict[\"<PAD>\"] = 0\n",
    "\n",
    "labels_dict = {\n",
    "    'O': 1,\n",
    "    'B-ORG': 2,\n",
    "    'I-ORG': 3,\n",
    "    'B-PER': 4,\n",
    "    'I-PER': 5,\n",
    "    'B-LOC': 6,\n",
    "    'I-LOC': 7,\n",
    "    'B-MISC': 8,\n",
    "    'I-MISC': 9,\n",
    "    '<PAD>': 0\n",
    "}\n",
    "\n",
    "## 反向映射，便于输出结果\n",
    "words_dict2 = {}\n",
    "for i, word in enumerate(words):\n",
    "    words_dict2[i + 1] = word\n",
    "words_dict2[0] = \"<PAD>\"\n",
    "labels_dict2 = {\n",
    "    1: 'O',\n",
    "    2: 'B-ORG',\n",
    "    3: 'I-ORG',\n",
    "    4: 'B-PER',\n",
    "    5: 'I-PER',\n",
    "    6: 'B-LOC',\n",
    "    7: 'I-LOC',\n",
    "    8: 'B-MISC',\n",
    "    9: 'I-MISC',\n",
    "    0: '<PAD>'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(sentences):\n",
    "    data = []\n",
    "    for sentence in sentences:\n",
    "        input = [words_dict[i] for i in sentence[0].split()]\n",
    "        label = [labels_dict[i] for i in sentence[1]]\n",
    "        pad_num = 124 - input.__len__()\n",
    "        for i in range(pad_num):\n",
    "            input.append(words_dict[\"<PAD>\"])\n",
    "            label.append(labels_dict[\"<PAD>\"])\n",
    "        data.append((torch.LongTensor(input), torch.LongTensor(label)))\n",
    "    return data\n",
    "\n",
    "def data2Tensor(data_list: list, mode: str = \"train\"):\n",
    "    df = pd.read_json(\"/Users/zhangyuyao/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/3b589b8fb0516c8e072f981ad5ce1b32/Message/MessageTemp/9a8944b8b79ab3df4a4f9e99ebae488b/File/第一次作业布置22.09.27/data/conll03/{}.json\".format(mode))\n",
    "    read_sentence(df, data_list)\n",
    "    data = data_load(data_list)\n",
    "    data_tensor, label_tensor = data[0][0].view(1,-1), data[0][1].view(1,-1)\n",
    "    for i in data[1:]:\n",
    "        data_tensor = torch.concat((data_tensor, i[0].view(1, -1)), dim = 0)\n",
    "        label_tensor = torch.concat((label_tensor, i[1].view(1, -1)), dim = 0)\n",
    "    return data_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14040, 124]), torch.Size([14040, 124]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = []\n",
    "data_tensor, label_tensor = data2Tensor(train_sentences, mode=\"train\")\n",
    "data_tensor.size(), label_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练数据\n",
    "input = data_tensor.numpy()\n",
    "np.save(\"input_train.npy\", input)\n",
    "label = label_tensor.numpy()\n",
    "np.save(\"label_train.npy\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3452, 124]), torch.Size([3452, 124]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test_data\n",
    "test_sentences = []\n",
    "data_tensor, label_tensor = data2Tensor(test_sentences, mode=\"test\")\n",
    "data_tensor.size(), label_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存测试数据\n",
    "input = data_tensor.numpy()\n",
    "np.save(\"input_test.npy\", input)\n",
    "label = label_tensor.numpy()\n",
    "np.save(\"label_test.npy\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences = []\n",
    "data_tensor, label_tensor = data2Tensor(dev_sentences, mode=\"dev\")\n",
    "input = data_tensor.numpy()\n",
    "np.save(\"input_dev.npy\", input)\n",
    "label = label_tensor.numpy()\n",
    "np.save(\"label_dev.npy\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14040, 124]), torch.Size([14040, 124]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.LongTensor(np.load(\"input_train.npy\", allow_pickle=True))\n",
    "label_tensor = torch.LongTensor(np.load(\"label_train.npy\", allow_pickle=True))\n",
    "data_tensor.size()\n",
    "data_tensor.size(), label_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3452, 124]), torch.Size([3452, 124]))"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tensor = torch.LongTensor(np.load(\"input_test.npy\", allow_pickle=True))\n",
    "label_tensor = torch.LongTensor(np.load(\"label_test.npy\", allow_pickle=True))\n",
    "data_tensor.size()\n",
    "data_tensor.size(), label_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 双向LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_generator(Dataset):\n",
    "    def __init__(self, data_tensor, label_tensor):\n",
    "        super().__init__()\n",
    "        self.input = data_tensor\n",
    "        self.output = label_tensor\n",
    "        self.len = data_tensor.size()[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.input[index], self.output[index]\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, dict_size, embedding_size, hidden_size, output_size):\n",
    "        \"\"\"初始化参数：\n",
    "            dict_size：字典的大小\n",
    "            embedding_size：词向量的维数\n",
    "            hidden_size：隐向量的维数\n",
    "            output_size：标签的维数\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = Embedding(dict_size, embedding_size, padding_idx = dict_size - 1)\n",
    "        self.bilstm = nn.LSTM(embedding_size, hidden_size,\n",
    "                              batch_first = True,\n",
    "                              bidirectional = True)\n",
    "        self.linear = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "    def forward(self, input_tensor: torch.LongTensor, seq_length, hidden_cell = None):\n",
    "        batch_size = input_tensor.size()[0]\n",
    "        \n",
    "        if hidden_cell is None:\n",
    "            hidden_cell = (torch.zeros(2, batch_size, self.hidden_size), \n",
    "                           torch.zeros(2, batch_size, self.hidden_size))\n",
    "        \n",
    "        embbeding = self.embedding(input_tensor)\n",
    "        embbeding = pack_padded_sequence(embbeding, seq_length,\n",
    "                                         batch_first = True,\n",
    "                                         enforce_sorted = False)\n",
    "        \n",
    "        lstm_out, hidden_cell = self.bilstm(embbeding, hidden_cell)\n",
    "        lstm_out, _ = pad_packed_sequence(lstm_out, \n",
    "                                          batch_first = True,\n",
    "                                          total_length = 124)\n",
    "        \n",
    "        output = self.linear(lstm_out)\n",
    "        return output, hidden_cell\n",
    "    \n",
    "    def train(self, epochs: int, trainDataLoader: DataLoader):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr = 3)\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            Loss = 0\n",
    "            for data in trainDataLoader:\n",
    "                optimizer.zero_grad()\n",
    "                input, output = data\n",
    "                seq_length = torch.count_nonzero(output, dim = -1)\n",
    "                pred_output, _ = self(input, seq_length)\n",
    "                loss = criterion(pred_output.view(-1, 10), output.view(-1))\n",
    "                Loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            optimizer.step()\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.4f}'.format(Loss))\n",
    "                \n",
    "    def test(self, data_tensor):\n",
    "        seq_length = torch.count_nonzero(label_tensor, dim = -1)\n",
    "        output, _ = self(data_tensor, seq_length)\n",
    "        output = torch.argmax(output, dim = -1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14040"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset_generator(data_tensor, label_tensor)\n",
    "trainDataLoader = DataLoader(dataset, batch_size = 32, shuffle = True)\n",
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm = BiLSTM(dict_size = len(words_dict),\n",
    "                embedding_size = 512,\n",
    "                hidden_size = 256,\n",
    "                output_size = len(labels_dict)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [03:09<1:01:43, 38.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 loss = 6.6087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [06:57<1:06:59, 44.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 loss = 1.5170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [10:49<1:06:00, 46.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0015 loss = 0.4950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [14:44<1:02:44, 47.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0020 loss = 0.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [18:32<57:22, 45.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0025 loss = 0.1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [22:26<54:38, 46.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0030 loss = 0.1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [26:23<51:13, 47.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0035 loss = 0.0890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [30:19<48:05, 48.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0040 loss = 0.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [34:39<47:07, 51.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0045 loss = 0.0608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [38:55<42:41, 51.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 loss = 0.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [43:03<37:03, 49.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0055 loss = 0.0452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [47:06<32:26, 48.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0060 loss = 0.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [51:19<29:30, 50.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0065 loss = 0.0359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [55:35<25:35, 51.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0070 loss = 0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [59:46<21:08, 50.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0075 loss = 0.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [1:04:00<16:54, 50.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0080 loss = 0.0275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [1:08:13<12:40, 50.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0085 loss = 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [1:12:31<08:32, 51.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0090 loss = 0.0240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [1:16:44<04:12, 50.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0095 loss = 0.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:21:01<00:00, 48.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0100 loss = 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bilstm.train(epochs = 100, trainDataLoader = trainDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "torch.save(bilstm.state_dict(), \"bilstm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = BiLSTM(dict_size = len(words_dict),\n",
    "                embedding_size = 512,\n",
    "                hidden_size = 256,\n",
    "                output_size = len(labels_dict)\n",
    "                )\n",
    "new_model.load_state_dict(torch.load(\"bilstm.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.LongTensor(np.load(\"input_test.npy\", allow_pickle=True))\n",
    "label_tensor = torch.LongTensor(np.load(\"label_test.npy\", allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_lists = []\n",
    "pred_labels_tensor = bilstm.test(data_tensor)\n",
    "seq_length = torch.count_nonzero(label_tensor, dim = -1).tolist()\n",
    "for i, j in enumerate(seq_length):\n",
    "    tmp_sentence, tmp_label = data_tensor[i][:j].tolist(), pred_labels_tensor[i][:j].tolist()\n",
    "    res = []\n",
    "    for i, j in zip(tmp_sentence, tmp_label):\n",
    "        res.append(labels_dict2[j])\n",
    "    pred_labels_lists.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3452"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_labels_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隐马尔可夫模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []\n",
    "df = pd.read_json(\"/Users/zhangyuyao/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/3b589b8fb0516c8e072f981ad5ce1b32/Message/MessageTemp/9a8944b8b79ab3df4a4f9e99ebae488b/File/第一次作业布置22.09.27/data/conll03/train.json\")\n",
    "read_sentence(df, train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建用于隐马尔可夫模型的词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set()\n",
    "for sentence in all_sentences:\n",
    "    words_list = sentence[0].split()\n",
    "    for word in words_list :\n",
    "        words.add(word)\n",
    "\n",
    "words_dict_hmm = {}\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    words_dict_hmm[word] = i\n",
    "    \n",
    "labels_dict_hmm = {\n",
    "    'O': 0,\n",
    "    'B-ORG': 1,\n",
    "    'I-ORG': 2,\n",
    "    'B-PER': 3,\n",
    "    'I-PER': 4,\n",
    "    'B-LOC': 5,\n",
    "    'I-LOC': 6,\n",
    "    'B-MISC': 7,\n",
    "    'I-MISC': 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    def __init__(self, N, M):\n",
    "        \n",
    "        self.N = N \n",
    "        self.M = M\n",
    "        \n",
    "        # 0. 初始化转移概率矩阵、估计观测概率矩阵、初始状态概率向量\n",
    "        self.A = np.zeros((N, N))\n",
    "        self.B = np.zeros((N, M))\n",
    "        self.pi = np.zeros(N)\n",
    "    \n",
    "    def train(self, data_list: list, words_dict: dict, labels_dict: dict):\n",
    "        \"\"\"use corpus to train the hmm model.\n",
    "\n",
    "        Args:\n",
    "            data_list (list): each item is a list, item[0] is sentence and item[1] is label_list\n",
    "            words_dict (dict): the words_dict, mapping word to its token\n",
    "            labels_dict (dict): the labels_dict mapping label to its token\n",
    "        \"\"\"\n",
    "        \n",
    "        ## 1.估计转移概率矩阵\n",
    "        for data in data_list:\n",
    "            for i in range(len(data[1]) - 1):\n",
    "                current_id = labels_dict[data[1][i]]\n",
    "                next_id = labels_dict[data[1][i + 1]]\n",
    "                self.A[current_id][next_id] += 1\n",
    "        self.A[self.A == 0.] = 1e-10\n",
    "        self.A = self.A / self.A.sum(axis = 1, keepdims = True)\n",
    "        \n",
    "        ## 2.估计观测概率矩阵\n",
    "        ## 实质为根据频率派思想估计每个状态对应观测到各个观察值（词语）的概率\n",
    "        for data in data_list:\n",
    "            label_list = data[1]\n",
    "            word_list = data[0].split()\n",
    "            for label, word in zip(label_list, word_list):\n",
    "                label_id = labels_dict[label]\n",
    "                word_id = words_dict[word]\n",
    "                self.B[label_id][word_id] += 1\n",
    "        self.B[self.B == 0.] = 1e-10\n",
    "        self.B = self.B / self.B.sum(axis = 1, keepdims = True)\n",
    "        \n",
    "        ## 3.估计初始状态概率\n",
    "        ## 实质为根据频率派思想估计每个标签作为一个序列的首的概率\n",
    "        for data in data_list:\n",
    "            self.pi[labels_dict[data[1][0]]] += 1\n",
    "        self.pi[self.pi == 0.] = 1e-10\n",
    "        self.pi = self.pi / self.pi.sum()\n",
    "    \n",
    "    def decoding(self, sentence: str,\n",
    "                 words_dict: dict = words_dict_hmm,\n",
    "                 labels_dict: dict = labels_dict_hmm):\n",
    "        \"\"\"use Viterbi algorithm to decode the hidden_state into label_sequence\n",
    "\n",
    "        Args:\n",
    "            sentence (str): default.\n",
    "            words_dict (dict): the words_dict, mapping word to its token\n",
    "            labels_dict (dict): the labels_dict, mapping label to its token\n",
    "        \"\"\"\n",
    "        A = np.log(self.A)\n",
    "        B = np.log(self.B)\n",
    "        Bt = B.T\n",
    "        Pi = np.log(self.pi)\n",
    "        word_list = sentence.split()\n",
    "        seq_length = len(word_list)\n",
    "        viterbi_matrix = np.zeros((self.N, seq_length))\n",
    "        backpointer = torch.zeros(self.N, seq_length).long()\n",
    "        start_idx = words_dict.get(word_list[0], None)\n",
    "        \n",
    "        if start_idx is None:\n",
    "            bt = np.log(np.ones(self.N) / self.N)\n",
    "        else:\n",
    "            bt = Bt[start_idx]\n",
    "            \n",
    "        viterbi_matrix[:, 0] = Pi + bt\n",
    "        backpointer[:, 0] = -1\n",
    "        \n",
    "        for i in range(1, seq_length):\n",
    "            word_idx = words_dict.get(word_list[i], None)\n",
    "            \n",
    "            if word_idx is None:\n",
    "                bt = np.log(np.ones(self.N) / self.N)\n",
    "            else:\n",
    "                bt = Bt[word_idx]\n",
    "            for label_idx in range(self.N):\n",
    "                max_prob = np.max(viterbi_matrix[:, i - 1] + A[:, label_idx], axis = 0)\n",
    "                max_idx = np.argmax(viterbi_matrix[:, i - 1] + A[:, label_idx], axis = 0)\n",
    "                viterbi_matrix[label_idx, i] = max_prob + bt[label_idx]\n",
    "                backpointer[label_idx, i] = max_idx\n",
    "        \n",
    "        best_path_prob = np.max(viterbi_matrix[:, seq_length - 1], axis=0)\n",
    "        best_path_pointer = np.argmax(viterbi_matrix[:, seq_length - 1], axis=0)\n",
    "        best_path_pointer = best_path_pointer.item()\n",
    "        best_path = [best_path_pointer]\n",
    "        \n",
    "        for back_step in range(seq_length - 1, 0, -1):\n",
    "            best_path_pointer = backpointer[best_path_pointer, back_step]\n",
    "            best_path_pointer = best_path_pointer.item()\n",
    "            best_path.append(best_path_pointer)\n",
    "\n",
    "        id2label = dict((id, tag) for tag, id in labels_dict.items())\n",
    "        label_list = [id2label[id] for id in reversed(best_path)]\n",
    "        \n",
    "        return word_list, label_list\n",
    "\n",
    "\n",
    "## 评价指标预测及输出\n",
    "def ent_predict(label_list):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        label_list (list): the item of this list is label of entity\n",
    "\n",
    "    Returns:\n",
    "        Tuple(list, str): the list of entity format and string to output\n",
    "    \"\"\"\n",
    "    span_list_ORG = []\n",
    "    span_list_PER = []\n",
    "    span_list_LOC = []\n",
    "    span_list_MISC = []\n",
    "    res = []\n",
    "    for i, label in enumerate(label_list):\n",
    "        if label == \"B-ORG\":\n",
    "            for j, label in enumerate(label_list[i + 1:]):\n",
    "                if label != \"I-ORG\":\n",
    "                    span_list_ORG.append([i, i + j])\n",
    "                    break\n",
    "        \n",
    "        if label == \"B-PER\":\n",
    "            for j, label in enumerate(label_list[i + 1:]):\n",
    "                if label != \"I-PER\":\n",
    "                    span_list_PER.append([i, i + j])\n",
    "                    break\n",
    "                \n",
    "        if label == \"B-LOC\":\n",
    "            for j, label in enumerate(label_list[i + 1:]):\n",
    "                if label != \"I-LOC\":\n",
    "                    span_list_LOC.append([i, i + j])\n",
    "                    break\n",
    "        \n",
    "        if label == \"B-MISC\":\n",
    "            for j, label in enumerate(label_list[i + 1:]):\n",
    "                if label != \"I-MISC\":\n",
    "                    span_list_MISC.append([i, i + j])\n",
    "                    break\n",
    "        \n",
    "    for item in span_list_ORG:\n",
    "        res.append(('ORG', item[0], item[1]))\n",
    "    \n",
    "    for item in span_list_PER:\n",
    "        res.append(('PER', item[0], item[1]))\n",
    "    \n",
    "    for item in span_list_LOC:\n",
    "        res.append(('LOC', item[0], item[1]))\n",
    "        \n",
    "    for item in span_list_MISC:\n",
    "        res.append(('MISC', item[0], item[1]))\n",
    "    \n",
    "    return res, \"; \".join([str(it) for it in res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM(9, len(words_dict_hmm))\n",
    "hmm.train(train_sentences, words_dict_hmm, labels_dict_hmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型测试与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metrics(predict_list, golen_list):\n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    for res1, res2 in zip (predict_list, golen_list):\n",
    "        for res_1_item in res1:\n",
    "            if res_1_item in res2:\n",
    "                a += 1\n",
    "            else:\n",
    "                b += 1\n",
    "        for res_2_item in res2:\n",
    "            if res_2_item  not in res1:\n",
    "                c += 1\n",
    "    p = a / (a + c)\n",
    "    r = a / (a + b)\n",
    "    f1 = 2 * p * r / (p + r)\n",
    "    return p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = []\n",
    "df = pd.read_json(\"/Users/zhangyuyao/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/3b589b8fb0516c8e072f981ad5ce1b32/Message/MessageTemp/9a8944b8b79ab3df4a4f9e99ebae488b/File/第一次作业布置22.09.27/data/conll03/test.json\")\n",
    "read_sentence(df, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "golen_list = []\n",
    "for i in range(len(df)):\n",
    "    tmp = []\n",
    "    label_items = df.loc[i, \"labels\"]\n",
    "    for item in label_items: \n",
    "        name = item[\"entity_label\"]\n",
    "        if len(item[\"span_list\"]) > 0:\n",
    "            for span in item[\"span_list\"]:\n",
    "                start = span[0][0]\n",
    "                end = span[0][1]\n",
    "                tmp.append((name, start, end))\n",
    "    golen_list.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list_hmm = []\n",
    "for i in range(len(df)):\n",
    "    _ , label_list = hmm.decoding(df.loc[i, \"context\"])\n",
    "    result , _ = ent_predict(label_list)\n",
    "    predict_list_hmm.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list_bilstm = []\n",
    "for i in range(len(df)):\n",
    "    res , _ = ent_predict(pred_labels_lists[i])\n",
    "    predict_list_bilstm.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('PER', 2, 2), ('PER', 9, 9)],\n",
       " [],\n",
       " [('LOC', 0, 0), ('LOC', 2, 3)],\n",
       " [('LOC', 0, 0), ('LOC', 15, 15), ('MISC', 6, 7)],\n",
       " [('ORG', 1, 1)],\n",
       " [('PER', 18, 19), ('LOC', 0, 0), ('LOC', 16, 16), ('MISC', 34, 34)],\n",
       " [('PER', 1, 1)],\n",
       " [('MISC', 2, 2), ('MISC', 8, 9)],\n",
       " [('MISC', 3, 4)],\n",
       " [('LOC', 11, 11), ('LOC', 26, 26)],\n",
       " [('PER', 0, 1)],\n",
       " [('LOC', 7, 7)],\n",
       " [('PER', 0, 0), ('PER', 1, 1), ('LOC', 27, 27)],\n",
       " [('MISC', 0, 0)],\n",
       " [('LOC', 0, 0), ('MISC', 6, 6), ('MISC', 18, 18)],\n",
       " [('PER', 0, 0)],\n",
       " [('PER', 2, 3), ('LOC', 0, 0)],\n",
       " [('MISC', 1, 1)],\n",
       " [],\n",
       " [('ORG', 16, 16), ('LOC', 0, 0), ('LOC', 8, 8), ('MISC', 5, 6)],\n",
       " [('PER', 0, 0),\n",
       "  ('LOC', 0, 0),\n",
       "  ('LOC', 1, 1),\n",
       "  ('LOC', 3, 3),\n",
       "  ('LOC', 5, 6),\n",
       "  ('LOC', 9, 9)],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('PER', 0, 0)],\n",
       " [('LOC', 0, 0)],\n",
       " [('LOC', 6, 6)],\n",
       " [('PER', 4, 5), ('LOC', 30, 30)],\n",
       " [('PER', 15, 15), ('LOC', 23, 23)],\n",
       " [('LOC', 19, 19), ('LOC', 23, 23), ('MISC', 7, 8)],\n",
       " [('PER', 0, 0)],\n",
       " [('PER', 12, 12), ('MISC', 4, 5)],\n",
       " [],\n",
       " [],\n",
       " [('PER', 2, 3),\n",
       "  ('PER', 5, 5),\n",
       "  ('PER', 8, 9),\n",
       "  ('PER', 11, 12),\n",
       "  ('PER', 14, 14),\n",
       "  ('PER', 17, 17),\n",
       "  ('PER', 20, 21),\n",
       "  ('PER', 23, 24),\n",
       "  ('PER', 27, 27),\n",
       "  ('PER', 29, 30),\n",
       "  ('PER', 35, 36),\n",
       "  ('PER', 38, 38),\n",
       "  ('PER', 41, 42),\n",
       "  ('PER', 45, 46),\n",
       "  ('PER', 48, 49),\n",
       "  ('PER', 51, 52),\n",
       "  ('PER', 54, 55),\n",
       "  ('PER', 57, 58),\n",
       "  ('PER', 60, 60),\n",
       "  ('PER', 63, 64)],\n",
       " [],\n",
       " [('LOC', 0, 0), ('LOC', 2, 3)],\n",
       " [('LOC', 17, 17), ('MISC', 11, 11), ('MISC', 13, 14)],\n",
       " [('PER', 16, 17)],\n",
       " [('MISC', 4, 4)],\n",
       " [('PER', 0, 0), ('PER', 1, 1), ('LOC', 27, 27)],\n",
       " [('LOC', 0, 0)],\n",
       " [('ORG', 17, 17), ('LOC', 0, 0)],\n",
       " [('LOC', 0, 0), ('MISC', 6, 6)],\n",
       " [('PER', 14, 14)],\n",
       " [],\n",
       " [('LOC', 0, 0)],\n",
       " [('ORG', 40, 40),\n",
       "  ('PER', 4, 4),\n",
       "  ('PER', 9, 10),\n",
       "  ('PER', 19, 20),\n",
       "  ('PER', 24, 25),\n",
       "  ('PER', 34, 34),\n",
       "  ('PER', 39, 39),\n",
       "  ('PER', 46, 47),\n",
       "  ('PER', 52, 52),\n",
       "  ('PER', 56, 57),\n",
       "  ('PER', 66, 66),\n",
       "  ('LOC', 0, 0)],\n",
       " [('PER', 14, 15),\n",
       "  ('PER', 36, 36),\n",
       "  ('PER', 41, 42),\n",
       "  ('PER', 46, 46),\n",
       "  ('PER', 64, 65),\n",
       "  ('PER', 69, 70),\n",
       "  ('LOC', 0, 0)],\n",
       " [('MISC', 0, 0), ('MISC', 1, 1), ('MISC', 2, 2)],\n",
       " [('LOC', 0, 0), ('LOC', 2, 2)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('PER', 1, 2), ('LOC', 4, 4)],\n",
       " [('MISC', 2, 3)],\n",
       " [('LOC', 0, 0), ('LOC', 2, 3)],\n",
       " [('MISC', 2, 3)],\n",
       " [('ORG', 0, 0), ('LOC', 2, 2)],\n",
       " [],\n",
       " [('PER', 2, 4), ('LOC', 0, 0)],\n",
       " [('PER', 2, 2), ('LOC', 0, 0)],\n",
       " [],\n",
       " [('ORG', 0, 0), ('ORG', 2, 2)],\n",
       " [('PER', 6, 6)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('LOC', 0, 0)],\n",
       " [('LOC', 0, 0)],\n",
       " [('LOC', 0, 0)],\n",
       " [('LOC', 2, 2), ('LOC', 4, 5)],\n",
       " [('MISC', 3, 3)],\n",
       " [('LOC', 2, 2)],\n",
       " [],\n",
       " [('LOC', 4, 4)],\n",
       " [],\n",
       " [],\n",
       " [('PER', 0, 1)],\n",
       " [('PER', 0, 0), ('PER', 3, 3)],\n",
       " [('PER', 0, 1), ('PER', 3, 3), ('PER', 5, 5)],\n",
       " [('ORG', 0, 0), ('ORG', 3, 3), ('PER', 0, 0), ('PER', 1, 1)],\n",
       " [('PER', 0, 1), ('PER', 3, 3)],\n",
       " [('ORG', 3, 3), ('PER', 0, 0), ('PER', 1, 1)],\n",
       " [('ORG', 5, 5), ('PER', 0, 1)],\n",
       " [('ORG', 3, 3), ('ORG', 5, 5), ('PER', 0, 1)],\n",
       " [('PER', 0, 1), ('PER', 3, 3)],\n",
       " [('PER', 0, 1)],\n",
       " [('PER', 0, 1)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 14, 14)],\n",
       " [('ORG', 8, 8), ('ORG', 11, 12), ('PER', 2, 2)],\n",
       " [('PER', 0, 1), ('PER', 6, 7), ('PER', 9, 10), ('LOC', 3, 3)],\n",
       " [('ORG', 0, 0), ('ORG', 1, 1)],\n",
       " [('LOC', 0, 1)],\n",
       " [('PER', 0, 1), ('PER', 3, 4), ('PER', 6, 6)],\n",
       " [('PER', 0, 1), ('PER', 3, 4), ('PER', 6, 6)],\n",
       " [('PER', 0, 1), ('PER', 3, 3)],\n",
       " [('PER', 0, 1)],\n",
       " [('PER', 0, 1), ('PER', 3, 3)],\n",
       " [('PER', 0, 0), ('PER', 3, 3), ('PER', 6, 7)],\n",
       " [('PER', 0, 1), ('PER', 4, 4)],\n",
       " [('ORG', 4, 4)],\n",
       " [('PER', 0, 1), ('PER', 3, 4), ('PER', 6, 6)],\n",
       " [('PER', 0, 1), ('PER', 5, 6), ('PER', 9, 9)],\n",
       " [('PER', 0, 1)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('PER', 2, 3)],\n",
       " [('PER', 0, 0), ('PER', 7, 9)],\n",
       " [('PER', 5, 5), ('PER', 6, 7), ('PER', 9, 10)],\n",
       " [('PER', 0, 0)],\n",
       " [('LOC', 2, 2)],\n",
       " [('LOC', 8, 8)],\n",
       " [('MISC', 2, 2), ('MISC', 4, 4)],\n",
       " [('LOC', 0, 0)],\n",
       " [('MISC', 3, 3)],\n",
       " [('MISC', 0, 0)],\n",
       " [('ORG', 0, 0), ('ORG', 2, 2)],\n",
       " [('PER', 2, 2), ('PER', 3, 3)],\n",
       " [('LOC', 0, 0)],\n",
       " [('ORG', 0, 0), ('ORG', 23, 23), ('PER', 10, 10), ('MISC', 19, 19)],\n",
       " [('ORG', 31, 31)],\n",
       " [('ORG', 15, 15), ('PER', 0, 0), ('LOC', 9, 9)],\n",
       " [('MISC', 4, 4)],\n",
       " [('ORG', 0, 0), ('ORG', 22, 22), ('MISC', 4, 4)],\n",
       " [('PER', 2, 2)],\n",
       " [('LOC', 0, 0)],\n",
       " [('ORG', 0, 0), ('PER', 5, 6), ('LOC', 2, 2)],\n",
       " [('LOC', 25, 25)],\n",
       " [('LOC', 24, 24)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 25, 25), ('MISC', 6, 6)],\n",
       " [],\n",
       " [('LOC', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 1), ('ORG', 3, 3)],\n",
       " [('PER', 0, 0), ('LOC', 3, 3)],\n",
       " [('ORG', 4, 4), ('PER', 1, 1)],\n",
       " [('ORG', 0, 0), ('LOC', 3, 3)],\n",
       " [('PER', 0, 0), ('LOC', 2, 2)],\n",
       " [('ORG', 0, 0), ('LOC', 2, 2)],\n",
       " [],\n",
       " [('PER', 0, 0), ('PER', 1, 1), ('LOC', 3, 3)],\n",
       " [('ORG', 0, 0), ('LOC', 2, 2)],\n",
       " [('ORG', 3, 3), ('PER', 0, 1)],\n",
       " [('ORG', 0, 0), ('LOC', 3, 3)],\n",
       " [('ORG', 0, 1), ('LOC', 3, 3)],\n",
       " [('PER', 0, 0), ('LOC', 2, 2)],\n",
       " [],\n",
       " [('ORG', 0, 0), ('LOC', 2, 2)],\n",
       " [('ORG', 0, 0), ('LOC', 2, 2)],\n",
       " [('PER', 0, 0), ('LOC', 2, 2)],\n",
       " [('ORG', 0, 0), ('LOC', 2, 2)],\n",
       " [('ORG', 0, 0), ('ORG', 2, 2)],\n",
       " [('PER', 0, 1), ('LOC', 3, 3)],\n",
       " [],\n",
       " [('ORG', 0, 1), ('LOC', 3, 3)],\n",
       " [('PER', 0, 0), ('LOC', 2, 2)],\n",
       " [('ORG', 0, 1), ('LOC', 3, 3)],\n",
       " [('PER', 0, 1), ('LOC', 3, 3)],\n",
       " [('ORG', 0, 0), ('LOC', 2, 2)],\n",
       " [('ORG', 0, 1), ('LOC', 3, 3)],\n",
       " [('ORG', 0, 1), ('ORG', 5, 5)],\n",
       " [],\n",
       " [('LOC', 0, 0)],\n",
       " [('ORG', 0, 0), ('PER', 0, 0), ('PER', 1, 2), ('LOC', 5, 5)],\n",
       " [('PER', 0, 0), ('PER', 27, 28)],\n",
       " [('LOC', 15, 15)],\n",
       " [('PER', 31, 31), ('MISC', 14, 14), ('MISC', 42, 43)],\n",
       " [('LOC', 29, 29)],\n",
       " [('ORG', 0, 0),\n",
       "  ('PER', 14, 15),\n",
       "  ('LOC', 21, 21),\n",
       "  ('LOC', 34, 35),\n",
       "  ('MISC', 30, 31)],\n",
       " [('PER', 27, 27)],\n",
       " [('LOC', 3, 3),\n",
       "  ('LOC', 10, 10),\n",
       "  ('LOC', 12, 12),\n",
       "  ('LOC', 14, 14),\n",
       "  ('LOC', 16, 16)],\n",
       " [('ORG', 0, 0),\n",
       "  ('PER', 17, 18),\n",
       "  ('PER', 22, 23),\n",
       "  ('PER', 29, 30),\n",
       "  ('PER', 32, 33),\n",
       "  ('LOC', 15, 15)],\n",
       " [],\n",
       " [('ORG', 15, 15),\n",
       "  ('ORG', 96, 96),\n",
       "  ('ORG', 104, 104),\n",
       "  ('PER', 4, 5),\n",
       "  ('PER', 12, 13),\n",
       "  ('PER', 20, 21),\n",
       "  ('PER', 28, 29),\n",
       "  ('PER', 36, 37),\n",
       "  ('PER', 44, 45),\n",
       "  ('PER', 52, 53),\n",
       "  ('PER', 60, 61),\n",
       "  ('PER', 68, 69),\n",
       "  ('PER', 76, 77),\n",
       "  ('PER', 84, 85),\n",
       "  ('PER', 93, 94),\n",
       "  ('PER', 101, 102),\n",
       "  ('PER', 109, 110),\n",
       "  ('PER', 118, 119),\n",
       "  ('LOC', 7, 7),\n",
       "  ('LOC', 23, 23),\n",
       "  ('LOC', 31, 31),\n",
       "  ('LOC', 39, 39),\n",
       "  ('LOC', 47, 47),\n",
       "  ('LOC', 55, 55),\n",
       "  ('LOC', 63, 63),\n",
       "  ('LOC', 71, 71),\n",
       "  ('LOC', 87, 88),\n",
       "  ('LOC', 112, 113),\n",
       "  ('LOC', 121, 121)],\n",
       " [('PER', 9, 9),\n",
       "  ('PER', 14, 15),\n",
       "  ('PER', 19, 20),\n",
       "  ('PER', 27, 28),\n",
       "  ('PER', 32, 33),\n",
       "  ('PER', 37, 38),\n",
       "  ('PER', 42, 43),\n",
       "  ('PER', 47, 48),\n",
       "  ('PER', 57, 58),\n",
       "  ('PER', 62, 63),\n",
       "  ('PER', 67, 68),\n",
       "  ('PER', 72, 73),\n",
       "  ('PER', 77, 78),\n",
       "  ('LOC', 0, 0)],\n",
       " [('MISC', 2, 3)],\n",
       " [],\n",
       " [('PER', 25, 25),\n",
       "  ('PER', 29, 30),\n",
       "  ('PER', 37, 38),\n",
       "  ('PER', 43, 44),\n",
       "  ('PER', 51, 52),\n",
       "  ('LOC', 32, 32),\n",
       "  ('LOC', 46, 46),\n",
       "  ('MISC', 6, 7),\n",
       "  ('MISC', 10, 11),\n",
       "  ('MISC', 12, 12),\n",
       "  ('MISC', 17, 18)],\n",
       " [('PER', 0, 1),\n",
       "  ('PER', 8, 9),\n",
       "  ('PER', 16, 17),\n",
       "  ('PER', 26, 27),\n",
       "  ('PER', 32, 34),\n",
       "  ('LOC', 3, 3),\n",
       "  ('LOC', 11, 11),\n",
       "  ('LOC', 36, 36)],\n",
       " [('PER', 0, 0), ('PER', 4, 5), ('PER', 9, 10)],\n",
       " [('PER', 2, 2), ('PER', 11, 14), ('PER', 21, 21), ('LOC', 16, 16)],\n",
       " [('PER', 2, 3),\n",
       "  ('PER', 5, 5),\n",
       "  ('PER', 10, 11),\n",
       "  ('PER', 19, 19),\n",
       "  ('LOC', 13, 13)],\n",
       " [('PER', 0, 1), ('PER', 5, 7)],\n",
       " [('LOC', 2, 2)],\n",
       " [('PER', 0, 0)],\n",
       " [('LOC', 0, 0), ('LOC', 16, 16), ('MISC', 21, 22)],\n",
       " [('LOC', 27, 27), ('MISC', 1, 1), ('MISC', 22, 22)],\n",
       " [('PER', 0, 0), ('MISC', 17, 17)],\n",
       " [],\n",
       " [('MISC', 16, 17)],\n",
       " [('PER', 2, 3), ('MISC', 11, 11)],\n",
       " [],\n",
       " [('ORG', 5, 5), ('PER', 2, 2)],\n",
       " [('PER', 2, 2),\n",
       "  ('PER', 5, 6),\n",
       "  ('PER', 8, 9),\n",
       "  ('PER', 11, 12),\n",
       "  ('PER', 14, 15),\n",
       "  ('PER', 17, 18),\n",
       "  ('PER', 20, 21)],\n",
       " [('PER', 2, 3),\n",
       "  ('PER', 5, 6),\n",
       "  ('PER', 11, 12),\n",
       "  ('PER', 14, 15),\n",
       "  ('PER', 17, 18)],\n",
       " [('ORG', 5, 5), ('PER', 2, 2)],\n",
       " [],\n",
       " [('MISC', 2, 2)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0), ('ORG', 2, 2)],\n",
       " [('ORG', 0, 0), ('ORG', 2, 3)],\n",
       " [('LOC', 2, 2)],\n",
       " [],\n",
       " [],\n",
       " [('PER', 2, 2), ('LOC', 0, 0), ('LOC', 12, 12)],\n",
       " [('PER', 0, 0)],\n",
       " [('LOC', 0, 0), ('MISC', 14, 15)],\n",
       " [('PER', 1, 1)],\n",
       " [],\n",
       " [('PER', 7, 8)],\n",
       " [('PER', 0, 0), ('PER', 19, 19)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 15, 15), ('PER', 2, 2), ('PER', 12, 13), ('LOC', 6, 6)],\n",
       " [('LOC', 13, 13)],\n",
       " [],\n",
       " [('PER', 0, 0)],\n",
       " [('LOC', 0, 0), ('LOC', 5, 5), ('MISC', 17, 18)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('LOC', 4, 4), ('LOC', 6, 7)],\n",
       " [],\n",
       " [('PER', 0, 1), ('PER', 3, 3), ('PER', 5, 5)],\n",
       " [('PER', 0, 1), ('PER', 3, 4), ('PER', 6, 6)],\n",
       " [('ORG', 0, 0), ('PER', 3, 3), ('PER', 5, 5)],\n",
       " [('PER', 0, 1), ('PER', 3, 3), ('PER', 5, 5)],\n",
       " [('PER', 0, 1)],\n",
       " [('PER', 0, 1), ('PER', 4, 4)],\n",
       " [('PER', 0, 1), ('PER', 5, 5)],\n",
       " [('PER', 0, 0), ('PER', 5, 6)],\n",
       " [('PER', 0, 1), ('PER', 3, 3)],\n",
       " [('PER', 0, 1)],\n",
       " [('PER', 0, 1)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('PER', 2, 3), ('PER', 8, 9)],\n",
       " [('PER', 0, 1), ('PER', 3, 3), ('PER', 6, 7)],\n",
       " [('PER', 0, 1)],\n",
       " [],\n",
       " [('PER', 0, 1)],\n",
       " [('PER', 0, 1), ('PER', 3, 3), ('PER', 5, 5)],\n",
       " [('PER', 0, 0)],\n",
       " [('PER', 0, 0)],\n",
       " [('ORG', 5, 5), ('PER', 0, 1), ('PER', 3, 3)],\n",
       " [('PER', 0, 1), ('PER', 3, 3)],\n",
       " [('PER', 0, 1)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('PER', 4, 5), ('PER', 7, 8), ('PER', 10, 11), ('PER', 13, 14)],\n",
       " [('PER', 2, 3), ('PER', 9, 10)],\n",
       " [('PER', 0, 1), ('PER', 7, 8)],\n",
       " [],\n",
       " [('LOC', 2, 2)],\n",
       " [('LOC', 2, 2), ('MISC', 4, 4)],\n",
       " [],\n",
       " [('LOC', 0, 0), ('LOC', 2, 3), ('LOC', 16, 16), ('MISC', 9, 10)],\n",
       " [('ORG', 11, 11), ('ORG', 16, 16), ('PER', 22, 22), ('MISC', 2, 2)],\n",
       " [('MISC', 2, 2), ('MISC', 8, 8)],\n",
       " [],\n",
       " [('LOC', 18, 18), ('MISC', 0, 0), ('MISC', 12, 13)],\n",
       " [],\n",
       " [('ORG', 0, 0), ('LOC', 2, 2)],\n",
       " [('LOC', 16, 16), ('LOC', 17, 17)],\n",
       " [('PER', 5, 5), ('PER', 11, 13), ('PER', 17, 18)],\n",
       " [('MISC', 6, 6)],\n",
       " [],\n",
       " [('PER', 3, 3), ('LOC', 0, 1), ('LOC', 32, 32), ('MISC', 10, 10)],\n",
       " [('PER', 0, 0), ('PER', 19, 20), ('LOC', 17, 17)],\n",
       " [('LOC', 1, 2)],\n",
       " [('PER', 20, 21), ('MISC', 0, 0)],\n",
       " [('LOC', 0, 0), ('MISC', 12, 12)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0), ('PER', 8, 8), ('MISC', 15, 15)],\n",
       " [('PER', 0, 0)],\n",
       " [('PER', 0, 0), ('LOC', 34, 34)],\n",
       " [('LOC', 0, 0), ('MISC', 25, 25)],\n",
       " [('PER', 0, 0), ('LOC', 12, 12)],\n",
       " [('LOC', 4, 4), ('MISC', 1, 1)],\n",
       " [('LOC', 0, 0), ('MISC', 13, 15)],\n",
       " [('MISC', 2, 2)],\n",
       " [],\n",
       " [('LOC', 24, 24), ('LOC', 27, 27), ('MISC', 0, 1), ('MISC', 18, 19)],\n",
       " [],\n",
       " [('PER', 2, 3),\n",
       "  ('PER', 8, 9),\n",
       "  ('PER', 11, 12),\n",
       "  ('PER', 14, 15),\n",
       "  ('PER', 17, 18),\n",
       "  ('PER', 20, 21),\n",
       "  ('PER', 23, 24),\n",
       "  ('PER', 26, 27),\n",
       "  ('PER', 29, 30),\n",
       "  ('PER', 32, 33),\n",
       "  ('PER', 35, 36),\n",
       "  ('PER', 38, 40),\n",
       "  ('LOC', 0, 0)],\n",
       " [('PER', 3, 4),\n",
       "  ('PER', 6, 7),\n",
       "  ('PER', 9, 10),\n",
       "  ('PER', 12, 13),\n",
       "  ('PER', 15, 16),\n",
       "  ('PER', 18, 19),\n",
       "  ('PER', 21, 22),\n",
       "  ('PER', 24, 25),\n",
       "  ('PER', 27, 27),\n",
       "  ('PER', 30, 31),\n",
       "  ('PER', 33, 34),\n",
       "  ('PER', 39, 40),\n",
       "  ('LOC', 0, 1)],\n",
       " [('MISC', 2, 2), ('MISC', 3, 4)],\n",
       " [],\n",
       " [('MISC', 9, 9), ('MISC', 10, 11)],\n",
       " [],\n",
       " [],\n",
       " [('PER', 0, 1), ('PER', 6, 8), ('LOC', 3, 3), ('LOC', 10, 10)],\n",
       " [('PER', 0, 1), ('PER', 6, 7), ('LOC', 3, 3), ('LOC', 9, 9)],\n",
       " [('PER', 0, 1), ('PER', 6, 8), ('LOC', 3, 3), ('LOC', 10, 10)],\n",
       " [],\n",
       " [('PER', 0, 1), ('PER', 6, 7), ('LOC', 3, 3), ('LOC', 9, 9)],\n",
       " [('PER', 0, 1), ('PER', 6, 8), ('LOC', 3, 3), ('LOC', 10, 10)],\n",
       " [],\n",
       " [('PER', 0, 0), ('PER', 1, 2), ('PER', 7, 8), ('LOC', 4, 4), ('LOC', 10, 10)],\n",
       " [('PER', 0, 0), ('PER', 1, 1), ('PER', 6, 7), ('LOC', 3, 3), ('LOC', 9, 9)],\n",
       " [('PER', 6, 7), ('LOC', 9, 9)],\n",
       " [('ORG', 11, 11), ('PER', 0, 0), ('LOC', 2, 2), ('LOC', 8, 8)],\n",
       " [('LOC', 1, 1)],\n",
       " [],\n",
       " [],\n",
       " [('PER', 0, 1), ('PER', 6, 7), ('LOC', 3, 3), ('LOC', 9, 9)],\n",
       " [],\n",
       " [('PER', 0, 1), ('PER', 6, 6), ('LOC', 3, 3), ('LOC', 8, 8)],\n",
       " [],\n",
       " [('PER', 0, 1), ('PER', 6, 7), ('LOC', 3, 3), ('LOC', 9, 9)],\n",
       " [],\n",
       " [('PER', 0, 1), ('PER', 6, 7), ('LOC', 3, 3), ('LOC', 9, 9)],\n",
       " [('ORG', 6, 7),\n",
       "  ('PER', 12, 13),\n",
       "  ('PER', 18, 19),\n",
       "  ('PER', 24, 25),\n",
       "  ('LOC', 9, 9),\n",
       "  ('LOC', 15, 15),\n",
       "  ('LOC', 21, 21),\n",
       "  ('LOC', 27, 27)],\n",
       " [('MISC', 2, 2), ('MISC', 5, 9)],\n",
       " [],\n",
       " [('ORG', 20, 21),\n",
       "  ('ORG', 26, 26),\n",
       "  ('LOC', 15, 16),\n",
       "  ('LOC', 23, 23),\n",
       "  ('LOC', 28, 28),\n",
       "  ('MISC', 7, 11)],\n",
       " [],\n",
       " [('PER', 0, 1), ('PER', 7, 8)],\n",
       " [],\n",
       " [],\n",
       " [('LOC', 0, 1)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('MISC', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('LOC', 0, 0)],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0), ('LOC', 2, 2)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [('MISC', 3, 3)],\n",
       " [('LOC', 0, 1)],\n",
       " [('ORG', 15, 15)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0), ('ORG', 2, 2)],\n",
       " [('ORG', 0, 0), ('ORG', 2, 3)],\n",
       " [('ORG', 0, 1), ('ORG', 3, 3)],\n",
       " [('ORG', 0, 0), ('ORG', 2, 3)],\n",
       " [('ORG', 0, 1), ('ORG', 3, 4)],\n",
       " [('LOC', 8, 8)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 21, 21), ('MISC', 2, 2)],\n",
       " [('ORG', 10, 10), ('ORG', 32, 32), ('PER', 0, 0)],\n",
       " [('PER', 0, 1), ('PER', 7, 8), ('PER', 11, 11)],\n",
       " [('ORG', 0, 0), ('ORG', 8, 8), ('LOC', 5, 6)],\n",
       " [('MISC', 1, 1)],\n",
       " [('ORG', 0, 0), ('ORG', 23, 25), ('LOC', 14, 14)],\n",
       " [('ORG', 3, 3)],\n",
       " [],\n",
       " [('MISC', 16, 16)],\n",
       " [('PER', 0, 0), ('PER', 7, 7)],\n",
       " [('PER', 0, 0)],\n",
       " [('PER', 0, 0), ('PER', 2, 2), ('PER', 26, 27)],\n",
       " [('ORG', 5, 5), ('MISC', 1, 1)],\n",
       " [('LOC', 0, 0)],\n",
       " [('PER', 0, 1), ('PER', 20, 20)],\n",
       " [('ORG', 0, 0)],\n",
       " [('LOC', 0, 1)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('MISC', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [],\n",
       " [],\n",
       " [('MISC', 0, 0)],\n",
       " [('ORG', 0, 0), ('ORG', 3, 3)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0), ('ORG', 3, 3)],\n",
       " [('ORG', 0, 0)],\n",
       " [('LOC', 0, 0)],\n",
       " [('PER', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('LOC', 0, 0)],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [('LOC', 0, 1)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('PER', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('MISC', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [('PER', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0), ('PER', 4, 4)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0), ('ORG', 1, 1)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1), ('ORG', 3, 3)],\n",
       " [],\n",
       " [('ORG', 2, 2)],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0), ('LOC', 2, 2)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 1, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('LOC', 0, 1)],\n",
       " [('LOC', 2, 2)],\n",
       " [],\n",
       " [('ORG', 0, 0), ('ORG', 2, 2)],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 19, 19), ('LOC', 0, 0), ('LOC', 22, 22)],\n",
       " [('ORG', 18, 18), ('PER', 6, 6), ('MISC', 17, 17)],\n",
       " [('MISC', 5, 5)],\n",
       " [],\n",
       " [('ORG', 6, 6), ('ORG', 15, 15), ('LOC', 25, 25)],\n",
       " [('MISC', 27, 27)],\n",
       " [('MISC', 2, 2)],\n",
       " [('PER', 0, 0)],\n",
       " [('MISC', 2, 2)],\n",
       " [],\n",
       " [('ORG', 0, 1), ('ORG', 3, 5)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1), ('ORG', 2, 2)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 3)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('MISC', 2, 2)],\n",
       " [('LOC', 0, 0)],\n",
       " [('MISC', 2, 2)],\n",
       " [],\n",
       " [('ORG', 0, 0), ('ORG', 2, 3)],\n",
       " [('ORG', 0, 1), ('ORG', 3, 4)],\n",
       " [('ORG', 0, 0), ('ORG', 2, 2)],\n",
       " [('ORG', 0, 0), ('ORG', 2, 3)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 2)],\n",
       " [('PER', 1, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 0), ('ORG', 1, 2)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 0, 0), ('ORG', 1, 1)],\n",
       " [('MISC', 2, 2)],\n",
       " [('LOC', 0, 0)],\n",
       " [('MISC', 2, 2)],\n",
       " [],\n",
       " [('ORG', 0, 0), ('ORG', 2, 2)],\n",
       " [('PER', 0, 0), ('PER', 3, 4)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 2), ('ORG', 9, 9), ('PER', 5, 5)],\n",
       " [('PER', 2, 3)],\n",
       " [],\n",
       " [],\n",
       " [('MISC', 2, 2)],\n",
       " [('PER', 0, 0)],\n",
       " [('MISC', 2, 2)],\n",
       " [],\n",
       " [('ORG', 0, 1), ('ORG', 7, 7)],\n",
       " [('PER', 0, 2)],\n",
       " [],\n",
       " [],\n",
       " [('MISC', 2, 2)],\n",
       " [('LOC', 0, 0)],\n",
       " [('MISC', 3, 3)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('MISC', 2, 2)],\n",
       " [('LOC', 0, 0)],\n",
       " [('MISC', 2, 2)],\n",
       " [],\n",
       " [('ORG', 0, 0), ('ORG', 2, 2)],\n",
       " [('ORG', 0, 2), ('ORG', 4, 4)],\n",
       " [('MISC', 2, 2)],\n",
       " [('LOC', 0, 0)],\n",
       " [('MISC', 6, 6)],\n",
       " [('PER', 14, 14), ('PER', 17, 17)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 1), ('ORG', 4, 4), ('ORG', 7, 8)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0), ('ORG', 12, 12), ('PER', 6, 6), ('PER', 9, 9)],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 0), ('ORG', 8, 9), ('PER', 3, 4)],\n",
       " [],\n",
       " [],\n",
       " [('MISC', 2, 4)],\n",
       " [('LOC', 0, 0), ('LOC', 2, 2)],\n",
       " [('PER', 15, 16),\n",
       "  ('PER', 21, 22),\n",
       "  ('LOC', 18, 18),\n",
       "  ('LOC', 24, 24),\n",
       "  ('MISC', 7, 9)],\n",
       " [('PER', 0, 1), ('PER', 6, 7), ('LOC', 3, 3), ('LOC', 9, 9)],\n",
       " [],\n",
       " [('PER', 0, 0)],\n",
       " [('PER', 6, 8),\n",
       "  ('PER', 25, 26),\n",
       "  ('PER', 41, 42),\n",
       "  ('LOC', 0, 0),\n",
       "  ('LOC', 13, 13),\n",
       "  ('MISC', 16, 17),\n",
       "  ('MISC', 39, 39)],\n",
       " [('ORG', 10, 10), ('LOC', 0, 0), ('MISC', 15, 16)],\n",
       " [('LOC', 0, 0), ('LOC', 16, 16), ('LOC', 21, 21), ('MISC', 2, 2)],\n",
       " [('LOC', 3, 3), ('MISC', 1, 1)],\n",
       " [],\n",
       " [('ORG', 5, 5),\n",
       "  ('ORG', 13, 13),\n",
       "  ('PER', 2, 3),\n",
       "  ('PER', 10, 11),\n",
       "  ('LOC', 7, 7)],\n",
       " [('ORG', 5, 5),\n",
       "  ('ORG', 18, 18),\n",
       "  ('ORG', 24, 24),\n",
       "  ('ORG', 30, 30),\n",
       "  ('ORG', 45, 45),\n",
       "  ('ORG', 50, 50),\n",
       "  ('ORG', 53, 54),\n",
       "  ('PER', 2, 3),\n",
       "  ('PER', 8, 9),\n",
       "  ('PER', 14, 16),\n",
       "  ('PER', 21, 22),\n",
       "  ('PER', 27, 28),\n",
       "  ('PER', 33, 34),\n",
       "  ('PER', 42, 43),\n",
       "  ('LOC', 36, 36),\n",
       "  ('LOC', 39, 39),\n",
       "  ('LOC', 47, 47),\n",
       "  ('LOC', 56, 56)],\n",
       " [('ORG', 5, 5),\n",
       "  ('ORG', 11, 11),\n",
       "  ('ORG', 17, 17),\n",
       "  ('PER', 2, 3),\n",
       "  ('PER', 8, 9),\n",
       "  ('PER', 14, 15),\n",
       "  ('PER', 20, 21),\n",
       "  ('PER', 28, 29),\n",
       "  ('LOC', 25, 25),\n",
       "  ('LOC', 31, 31),\n",
       "  ('LOC', 33, 33)],\n",
       " [('ORG', 5, 5),\n",
       "  ('ORG', 12, 12),\n",
       "  ('ORG', 18, 18),\n",
       "  ('ORG', 32, 32),\n",
       "  ('PER', 2, 3),\n",
       "  ('PER', 8, 10),\n",
       "  ('PER', 15, 16),\n",
       "  ('PER', 21, 22),\n",
       "  ('PER', 24, 24),\n",
       "  ('PER', 29, 30),\n",
       "  ('LOC', 26, 26),\n",
       "  ('LOC', 35, 35)],\n",
       " [('ORG', 4, 4)],\n",
       " [('PER', 0, 0)],\n",
       " [('PER', 0, 1)],\n",
       " [('ORG', 5, 6), ('ORG', 8, 8), ('MISC', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 1), ('ORG', 4, 4)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('PER', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 1, 2)],\n",
       " [],\n",
       " [],\n",
       " [('LOC', 1, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 1)],\n",
       " [('LOC', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 2)],\n",
       " [],\n",
       " [('PER', 1, 2)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('PER', 0, 1)],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [('PER', 1, 1)],\n",
       " [('PER', 1, 1)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('PER', 0, 0)],\n",
       " [('ORG', 26, 26), ('ORG', 28, 29), ('MISC', 0, 0)],\n",
       " [('MISC', 15, 15)],\n",
       " [],\n",
       " [('MISC', 2, 2)],\n",
       " [('PER', 0, 0)],\n",
       " [('MISC', 3, 3)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [('ORG', 0, 1), ('ORG', 2, 2)],\n",
       " [('ORG', 0, 2)],\n",
       " [('ORG', 1, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0), ('ORG', 1, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('PER', 0, 0)],\n",
       " [],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0), ('ORG', 1, 1)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 0, 0), ('ORG', 1, 1)],\n",
       " [('MISC', 7, 9)],\n",
       " [('PER', 0, 0)],\n",
       " [('PER', 2, 3),\n",
       "  ('PER', 10, 10),\n",
       "  ('LOC', 0, 0),\n",
       "  ('LOC', 21, 21),\n",
       "  ('MISC', 17, 18)],\n",
       " [],\n",
       " [('ORG', 13, 13), ('PER', 9, 9)],\n",
       " [('PER', 2, 2)],\n",
       " [('PER', 0, 0)],\n",
       " [('ORG', 11, 11),\n",
       "  ('PER', 0, 0),\n",
       "  ('PER', 2, 3),\n",
       "  ('PER', 13, 14),\n",
       "  ('PER', 30, 31),\n",
       "  ('MISC', 28, 28)],\n",
       " [('LOC', 25, 25), ('MISC', 5, 5)],\n",
       " [('PER', 23, 23)],\n",
       " [],\n",
       " [],\n",
       " [('PER', 0, 0), ('PER', 7, 7), ('PER', 9, 10)],\n",
       " [('MISC', 11, 12)],\n",
       " [],\n",
       " [('LOC', 6, 6), ('MISC', 9, 9)],\n",
       " [('LOC', 0, 0)],\n",
       " [('ORG', 0, 0), ('ORG', 6, 6), ('LOC', 14, 14)],\n",
       " [('MISC', 8, 9)],\n",
       " [('ORG', 0, 0), ('LOC', 3, 3)],\n",
       " [],\n",
       " [('ORG', 1, 1), ('MISC', 18, 18)],\n",
       " [('ORG', 20, 20)],\n",
       " [],\n",
       " [],\n",
       " [('LOC', 4, 4)],\n",
       " [('ORG', 0, 1)],\n",
       " [('MISC', 2, 2)],\n",
       " [('PER', 0, 0)],\n",
       " [('MISC', 0, 0), ('MISC', 19, 19)],\n",
       " [('ORG', 0, 0), ('ORG', 5, 5)],\n",
       " [('PER', 3, 3), ('PER', 5, 6), ('MISC', 13, 13)],\n",
       " [('ORG', 33, 34), ('LOC', 0, 0), ('MISC', 4, 4), ('MISC', 8, 10)],\n",
       " [('ORG', 0, 0), ('ORG', 5, 5)],\n",
       " [('PER', 24, 25), ('MISC', 22, 22)],\n",
       " [('PER', 0, 0), ('MISC', 10, 10)],\n",
       " [('ORG', 0, 0), ('ORG', 5, 5)],\n",
       " [('ORG', 0, 0),\n",
       "  ('ORG', 31, 31),\n",
       "  ('PER', 16, 17),\n",
       "  ('PER', 28, 28),\n",
       "  ('PER', 34, 35)],\n",
       " [('ORG', 0, 0), ('ORG', 6, 6), ('PER', 5, 5)],\n",
       " [('MISC', 3, 3), ('MISC', 21, 21), ('MISC', 23, 24)],\n",
       " [('ORG', 0, 0),\n",
       "  ('PER', 6, 6),\n",
       "  ('PER', 9, 9),\n",
       "  ('PER', 11, 11),\n",
       "  ('PER', 19, 19),\n",
       "  ('PER', 27, 27),\n",
       "  ('PER', 31, 32),\n",
       "  ('PER', 34, 35)],\n",
       " [('ORG', 0, 1), ('ORG', 6, 6)],\n",
       " [('ORG', 1, 1)],\n",
       " [('MISC', 8, 8)],\n",
       " [('ORG', 9, 9),\n",
       "  ('PER', 2, 3),\n",
       "  ('PER', 11, 12),\n",
       "  ('PER', 19, 19),\n",
       "  ('MISC', 15, 15)],\n",
       " [('ORG', 3, 3), ('ORG', 6, 6), ('PER', 10, 11), ('MISC', 8, 8)],\n",
       " [('ORG', 5, 5), ('PER', 0, 0)],\n",
       " [('PER', 19, 20), ('MISC', 17, 17)],\n",
       " [('PER', 0, 0)],\n",
       " [('ORG', 0, 0), ('ORG', 5, 5)],\n",
       " [('ORG', 0, 0), ('ORG', 8, 8)],\n",
       " [('ORG', 0, 0),\n",
       "  ('PER', 4, 5),\n",
       "  ('PER', 15, 15),\n",
       "  ('MISC', 2, 2),\n",
       "  ('MISC', 13, 13)],\n",
       " [],\n",
       " [('ORG', 0, 0), ('ORG', 5, 5)],\n",
       " [('PER', 0, 0), ('PER', 10, 10), ('PER', 17, 17), ('PER', 18, 18)],\n",
       " [('ORG', 21, 21), ('PER', 16, 17), ('PER', 23, 24)],\n",
       " [('ORG', 0, 0), ('ORG', 4, 4), ('ORG', 5, 5)],\n",
       " [],\n",
       " [('PER', 1, 1), ('PER', 2, 2), ('PER', 7, 8), ('PER', 10, 10)],\n",
       " [('PER', 7, 8), ('MISC', 5, 5), ('MISC', 11, 11)],\n",
       " [],\n",
       " [('LOC', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [('LOC', 1, 1)],\n",
       " [('PER', 0, 0), ('LOC', 2, 2), ('LOC', 8, 8)],\n",
       " [],\n",
       " [('PER', 2, 2),\n",
       "  ('PER', 3, 3),\n",
       "  ('PER', 6, 6),\n",
       "  ('PER', 10, 10),\n",
       "  ('LOC', 6, 6),\n",
       "  ('LOC', 7, 7)],\n",
       " [('PER', 2, 3), ('PER', 6, 6), ('PER', 10, 10)],\n",
       " [],\n",
       " [('LOC', 1, 1)],\n",
       " [('ORG', 0, 0), ('PER', 6, 7), ('LOC', 3, 3), ('LOC', 9, 9)],\n",
       " [],\n",
       " [('PER', 2, 3)],\n",
       " [('PER', 2, 3)],\n",
       " [('PER', 2, 2), ('PER', 4, 4)],\n",
       " [('LOC', 0, 0), ('LOC', 2, 2)],\n",
       " [('MISC', 34, 35)],\n",
       " [('PER', 6, 7), ('MISC', 1, 1)],\n",
       " [('ORG', 0, 0), ('LOC', 8, 8), ('LOC', 11, 12), ('LOC', 14, 14)],\n",
       " [],\n",
       " [],\n",
       " [('MISC', 2, 2)],\n",
       " [('LOC', 0, 0), ('LOC', 2, 2)],\n",
       " [],\n",
       " [('PER', 0, 1),\n",
       "  ('PER', 6, 7),\n",
       "  ('PER', 14, 15),\n",
       "  ('PER', 20, 21),\n",
       "  ('LOC', 3, 3),\n",
       "  ('LOC', 9, 9),\n",
       "  ('LOC', 17, 17),\n",
       "  ('LOC', 23, 23)],\n",
       " [('ORG', 4, 4)],\n",
       " [('PER', 1, 1)],\n",
       " [('LOC', 0, 0), ('LOC', 2, 3)],\n",
       " [('LOC', 14, 15)],\n",
       " [('ORG', 15, 17),\n",
       "  ('PER', 12, 13),\n",
       "  ('PER', 19, 19),\n",
       "  ('LOC', 34, 34),\n",
       "  ('LOC', 36, 36)],\n",
       " [],\n",
       " [('LOC', 21, 21)],\n",
       " [('ORG', 16, 16), ('PER', 13, 14)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('ORG', 25, 27)],\n",
       " [('MISC', 0, 0)],\n",
       " [],\n",
       " [],\n",
       " [('PER', 2, 3),\n",
       "  ('PER', 10, 11),\n",
       "  ('LOC', 16, 16),\n",
       "  ('LOC', 21, 22),\n",
       "  ('MISC', 0, 0)],\n",
       " [('PER', 15, 15)],\n",
       " [],\n",
       " [('LOC', 2, 3)],\n",
       " [('ORG', 12, 12), ('PER', 6, 6)],\n",
       " [('PER', 0, 0), ('LOC', 16, 16), ('MISC', 13, 13)],\n",
       " [('PER', 0, 0)],\n",
       " [('PER', 0, 0), ('LOC', 10, 10), ('LOC', 18, 19)],\n",
       " [('ORG', 20, 21), ('PER', 4, 4), ('LOC', 9, 9), ('LOC', 16, 16)],\n",
       " [('ORG', 14, 14), ('ORG', 18, 18), ('MISC', 0, 0), ('MISC', 34, 34)],\n",
       " [],\n",
       " [('ORG', 39, 39), ('PER', 36, 37), ('LOC', 28, 28)],\n",
       " [('ORG', 9, 9)],\n",
       " [('ORG', 4, 5), ('LOC', 0, 0), ('MISC', 13, 13)],\n",
       " [('ORG', 3, 3)],\n",
       " [('PER', 0, 0)],\n",
       " [('ORG', 0, 0), ('LOC', 0, 0), ('LOC', 1, 1)],\n",
       " [('ORG', 17, 19), ('ORG', 22, 22), ('ORG', 23, 24), ('MISC', 2, 3)],\n",
       " [],\n",
       " [('LOC', 16, 16)],\n",
       " [('PER', 17, 18), ('LOC', 13, 13)],\n",
       " [('LOC', 13, 13)],\n",
       " [('ORG', 1, 2)],\n",
       " [('MISC', 0, 0)],\n",
       " [],\n",
       " [('ORG', 7, 10), ('ORG', 12, 12)],\n",
       " [],\n",
       " [('ORG', 16, 16)],\n",
       " [('ORG', 18, 18), ('PER', 25, 26), ('LOC', 43, 43), ('LOC', 46, 46)],\n",
       " [],\n",
       " [('ORG', 1, 1), ('PER', 19, 20), ('MISC', 16, 16), ('MISC', 27, 27)],\n",
       " [('ORG', 23, 23)],\n",
       " [('LOC', 25, 25)],\n",
       " [],\n",
       " [('MISC', 23, 24)],\n",
       " [('ORG', 1, 2)],\n",
       " [('LOC', 0, 0)],\n",
       " [],\n",
       " [('LOC', 0, 0)],\n",
       " [('LOC', 0, 0), ('MISC', 5, 5), ('MISC', 15, 15), ('MISC', 34, 36)],\n",
       " [('PER', 2, 3), ('PER', 5, 5), ('LOC', 21, 21)],\n",
       " [('ORG', 7, 7), ('PER', 4, 4), ('LOC', 10, 10)],\n",
       " [('PER', 15, 15)],\n",
       " [('ORG', 12, 14),\n",
       "  ('PER', 4, 4),\n",
       "  ('PER', 5, 5),\n",
       "  ('PER', 12, 12),\n",
       "  ('PER', 15, 15),\n",
       "  ('LOC', 0, 0),\n",
       "  ('LOC', 48, 48),\n",
       "  ('MISC', 29, 29),\n",
       "  ('MISC', 39, 39)],\n",
       " [('LOC', 18, 18), ('MISC', 12, 12), ('MISC', 13, 13), ('MISC', 22, 22)],\n",
       " [('PER', 0, 0),\n",
       "  ('LOC', 16, 16),\n",
       "  ('LOC', 18, 18),\n",
       "  ('MISC', 22, 23),\n",
       "  ('MISC', 34, 36)],\n",
       " [('PER', 24, 24)],\n",
       " [('PER', 0, 0), ('LOC', 10, 10)],\n",
       " [('LOC', 6, 6)],\n",
       " [('ORG', 13, 13), ('MISC', 12, 12)],\n",
       " [('PER', 17, 17)],\n",
       " [('PER', 4, 4), ('MISC', 7, 7)],\n",
       " [('ORG', 2, 3),\n",
       "  ('ORG', 5, 5),\n",
       "  ('MISC', 17, 17),\n",
       "  ('MISC', 24, 24),\n",
       "  ('MISC', 39, 39)],\n",
       " [('MISC', 1, 1), ('MISC', 7, 7)],\n",
       " [],\n",
       " [('ORG', 0, 0)],\n",
       " [('LOC', 0, 0)],\n",
       " [('MISC', 0, 0)],\n",
       " [('ORG', 6, 6), ('PER', 2, 4)],\n",
       " [],\n",
       " [],\n",
       " [('PER', 0, 0), ('MISC', 20, 20)],\n",
       " [('PER', 26, 27), ('PER', 35, 35), ('MISC', 30, 30)],\n",
       " [('ORG', 19, 19), ('LOC', 22, 22), ('LOC', 29, 29), ('LOC', 31, 31)],\n",
       " [('PER', 0, 0), ('LOC', 3, 3), ('LOC', 7, 7)],\n",
       " [('ORG', 0, 0)],\n",
       " [('ORG', 5, 5),\n",
       "  ('PER', 18, 19),\n",
       "  ('LOC', 33, 33),\n",
       "  ('LOC', 42, 42),\n",
       "  ('MISC', 3, 4)],\n",
       " [('PER', 0, 1)],\n",
       " [],\n",
       " [('LOC', 35, 36)],\n",
       " [('PER', 22, 22), ('LOC', 5, 5), ('LOC', 6, 6), ('LOC', 33, 33)],\n",
       " [('MISC', 3, 3)],\n",
       " [('MISC', 15, 15)],\n",
       " [('PER', 0, 0)],\n",
       " [],\n",
       " [('PER', 18, 19), ('LOC', 31, 31), ('MISC', 9, 9)],\n",
       " [('PER', 0, 0), ('LOC', 35, 35)],\n",
       " [('ORG', 1, 2)],\n",
       " [('ORG', 0, 0)],\n",
       " [],\n",
       " [('PER', 9, 11), ('MISC', 7, 7)],\n",
       " [('PER', 10, 10)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('PER', 0, 0)],\n",
       " [],\n",
       " [('PER', 6, 6)],\n",
       " [('LOC', 9, 9)],\n",
       " [('LOC', 0, 0)],\n",
       " [('ORG', 1, 4), ('LOC', 20, 20), ('LOC', 40, 40)],\n",
       " [('ORG', 6, 6)],\n",
       " [],\n",
       " [],\n",
       " [('LOC', 6, 6)],\n",
       " [('LOC', 0, 0)],\n",
       " [('ORG', 0, 0), ('LOC', 10, 10)],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [('LOC', 1, 1)],\n",
       " [('LOC', 5, 5)],\n",
       " [('LOC', 0, 0)],\n",
       " [('LOC', 11, 11), ('MISC', 0, 2)],\n",
       " [],\n",
       " [],\n",
       " [('LOC', 7, 7)],\n",
       " [('PER', 3, 3)],\n",
       " ...]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_list_bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5761871013465627, 0.6407881773399015, 0.6067730198712565)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, r, f1 = Metrics(predict_list_hmm, golen_list)\n",
    "p, r, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5914245216158752, 0.7402971834109559, 0.6575396434551364)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, r, f1 = Metrics(predict_list_bilstm, golen_list)\n",
    "p, r, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resOutput(sentences: list, model = hmm, mode: str = \"hmm\", form: str = \"BIO\"):\n",
    "    if form == \"BIO\":\n",
    "        with open(\"{}_BIO_results.txt\".format(mode), \"w\") as f:\n",
    "            for sentence in sentences:\n",
    "                word_list, label_list = model.decoding(sentence[0])\n",
    "                assert len(word_list) == len(label_list)\n",
    "                for word, label in zip(word_list, label_list):\n",
    "                    f.write(word + \"\\t\" + label + \"\\n\")\n",
    "    else:\n",
    "        label_output = []\n",
    "        for i in range(len(df)):\n",
    "            out = {}\n",
    "            out[\"text\"] = df.loc[i, \"context\"]\n",
    "            \n",
    "            _ , label_list = model.decoding(df.loc[i, \"context\"])\n",
    "            _ , out[\"ent_predict\"] = ent_predict(label_list)\n",
    "            \n",
    "            tmp = []\n",
    "            label_items = df.loc[i, \"labels\"]\n",
    "            for item in label_items: \n",
    "                name = item[\"entity_label\"]\n",
    "                if len(item[\"span_list\"]) > 0:\n",
    "                    for span in item[\"span_list\"]:\n",
    "                        start = span[0][0]\n",
    "                        end = span[0][1]\n",
    "                        tmp.append((name, start, end))\n",
    "            out[\"golen_label\"] = \"; \".join([str(it) for it in tmp])\n",
    "            \n",
    "            label_output.append(out)\n",
    "            \n",
    "        with open('{}_Ent_results.json'.format(mode),'w') as f:\n",
    "            json.dump(label_output, f, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "resOutput(test_sentences, model=hmm)\n",
    "resOutput(test_sentences, model=hmm, form=\"Ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resOutput2(sentences: list, model = bilstm, form: str = \"BIO\"):\n",
    "    sentence_list = [i[0] for i in sentences]\n",
    "    if form == \"BIO\":\n",
    "        with open(\"bilstm_BIO_results.txt\", \"w\") as f:\n",
    "            for i, sentence in enumerate(sentence_list):\n",
    "                words_list = sentence.split()\n",
    "                labels_list = pred_labels_lists[i]\n",
    "                assert len(words_list) == len(labels_list)\n",
    "                for word, label in zip(words_list, labels_list):\n",
    "                    f.write(word + \"\\t\" + label + \"\\n\")\n",
    "    else:\n",
    "        label_output = []\n",
    "        for i in range(len(df)):\n",
    "            out = {}\n",
    "            out[\"text\"] = df.loc[i, \"context\"]\n",
    "            \n",
    "            label_list = pred_labels_lists[i]\n",
    "            _ , out[\"ent_predict\"] = ent_predict(label_list)\n",
    "            \n",
    "            tmp = []\n",
    "            label_items = df.loc[i, \"labels\"]\n",
    "            for item in label_items: \n",
    "                name = item[\"entity_label\"]\n",
    "                if len(item[\"span_list\"]) > 0:\n",
    "                    for span in item[\"span_list\"]:\n",
    "                        start = span[0][0]\n",
    "                        end = span[0][1]\n",
    "                        tmp.append((name, start, end))\n",
    "            out[\"golen_label\"] = \"; \".join([str(it) for it in tmp])\n",
    "            \n",
    "            label_output.append(out)\n",
    "            \n",
    "        with open('bilstm_Ent_results.json','w') as f:\n",
    "            json.dump(label_output, f, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "resOutput2(test_sentences)\n",
    "resOutput2(test_sentences, form=\"Ent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3d692901de45d9b4aaf7a5ac1f67fc2de64507a253b3ac3ff6362f89d8497a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
